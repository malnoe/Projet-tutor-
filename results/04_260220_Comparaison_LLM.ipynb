{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f190ed",
   "metadata": {},
   "source": [
    "# Etude de l'impact du choix du LLM sur les persformances\n",
    "Présentation de ce que l'on veut faire ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ea403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.oauth2 import service_account\n",
    "import hashlib\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import tomllib\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re\n",
    "from typing import Dict, Any\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75417c",
   "metadata": {},
   "source": [
    "## 1. Initialisation\n",
    "Nous commençons tout d'abord par importer les bibliothèques nécessaires et initialiser le client permettant d'accéder à un LLM via VertexAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Path jusqu'au fichier de clé JSON\n",
    "KEY_PATH = \"projet-tutore-uga-98c5d56c8a8e.json\"\n",
    "\n",
    "# 2. Credentials object\n",
    "SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
    "    KEY_PATH,\n",
    "    scopes=SCOPES\n",
    "    )\n",
    "\n",
    "# 3.Paramètres du projet\n",
    "PROJECT_ID = \"projet-tutore-uga\"\n",
    "REGION = \"global\"\n",
    "\n",
    "# 4. Initialisation du client GenAI\n",
    "client = genai.Client(\n",
    "    vertexai=True, project=PROJECT_ID, location=REGION, credentials=CREDENTIALS\n",
    ")\n",
    "\n",
    "# 5. Modèle\n",
    "MODEL_ID = \"gemini-3-pro-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1e3ac",
   "metadata": {},
   "source": [
    "## 2. Jeu de données\n",
    "Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0112890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: ..\\data\\01_251021_AvisFiscalite.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the URL and expected SHA-1 checksum\n",
    "url = \"https://www.data.gouv.fr/fr/datasets/r/bc085888-e6bd-445d-b3f4-632190c29e3f\"\n",
    "expected_sha1 = \"90540350af64eb61f8a9823c83468934b19634c1\"\n",
    "\n",
    "# Define the target directory and file path\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "file_path = data_dir / \"01_251021_AvisFiscalite.csv\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if file_path.exists():\n",
    "    print(f\"File already exists: {file_path}\")\n",
    "else:\n",
    "    # Download the file if it doesn't exist\n",
    "    print(f\"Downloading file: {file_path}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "    file_path.write_bytes(response.content)\n",
    "\n",
    "    # Verify the SHA-1 checksum\n",
    "    sha1 = hashlib.sha1()\n",
    "    with file_path.open(\"rb\") as f:\n",
    "        while chunk := f.read(8192):\n",
    "            sha1.update(chunk)\n",
    "    calculated_sha1 = sha1.hexdigest()\n",
    "    if calculated_sha1 == expected_sha1:\n",
    "        print(\"SHA-1 checksum verified successfully.\")\n",
    "    else:\n",
    "        print(f\"SHA-1 checksum mismatch! Expected: {expected_sha1}, Got: {calculated_sha1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111a67fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garan\\AppData\\Local\\Temp\\ipykernel_13492\\299903361.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "col_name = \"QUXVlc3Rpb246MTYz - Que faudrait-il faire pour rendre la fiscalité plus juste et plus efficace ?\"\n",
    "df_contrib = df[['authorId', col_name]].rename(\n",
    "    {col_name:'contribution'},\n",
    "    axis=1)\n",
    "df_contrib = df_contrib.dropna(subset=['contribution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e42f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorId</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VXNlcjpjNDY0ZjllMy0xZDk4LTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>Repartir les richesses.  suppression de la tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VXNlcjo3MDdkM2IzOC0xZDYxLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>Les droits soient automatiques, comme nos devo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VXNlcjoxZTNlOTExYi0xZTIwLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>réduire drastiquement la fraude fiscale. Impos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VXNlcjo1ODljMWRiMy0xZDVhLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>diminuer le taux de prelevement pour les retra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VXNlcjo0OTUzNmNmYy0xZTIwLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>TOUT FRANÇAIS DEVRA PAYER L’IMPÔT QU’IL SOIT D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            authorId  \\\n",
       "3  VXNlcjpjNDY0ZjllMy0xZDk4LTExZTktOTRkMi1mYTE2M2...   \n",
       "4  VXNlcjo3MDdkM2IzOC0xZDYxLTExZTktOTRkMi1mYTE2M2...   \n",
       "7  VXNlcjoxZTNlOTExYi0xZTIwLTExZTktOTRkMi1mYTE2M2...   \n",
       "8  VXNlcjo1ODljMWRiMy0xZDVhLTExZTktOTRkMi1mYTE2M2...   \n",
       "9  VXNlcjo0OTUzNmNmYy0xZTIwLTExZTktOTRkMi1mYTE2M2...   \n",
       "\n",
       "                                        contribution  \n",
       "3  Repartir les richesses.  suppression de la tax...  \n",
       "4  Les droits soient automatiques, comme nos devo...  \n",
       "7  réduire drastiquement la fraude fiscale. Impos...  \n",
       "8  diminuer le taux de prelevement pour les retra...  \n",
       "9  TOUT FRANÇAIS DEVRA PAYER L’IMPÔT QU’IL SOIT D...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contrib.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b67612",
   "metadata": {},
   "source": [
    "## 3. Extraction avec le nouveau LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ddbc4",
   "metadata": {},
   "source": [
    "Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4324c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMBadCSV(Exception):\n",
    "    pass\n",
    "\n",
    "# Fonction pour nettoyer les balises de code et autres ajouts indésirables\n",
    "def strip_code_fences(s: str) -> str:\n",
    "    # Supprime les balises de code Markdown\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"^```[a-zA-Z]*\\s*\", \"\", s)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "    # Supprime tout préfixe avant \"CSV:\" si ça arrive\n",
    "    idx = s.find(\"CSV:\")\n",
    "    if idx != -1:\n",
    "        s = s[idx:]\n",
    "    return s\n",
    "\n",
    "# Fonction pour extraire le bloc CSV du texte retourné par le LLM\n",
    "def extract_csv_block(s: str) -> str:\n",
    "    s = strip_code_fences(s)\n",
    "    # On vérifie si la sortie commence par \"CSV:\" comme on s'y attendd'après le prompt\n",
    "    if s.startswith(\"CSV:\"):\n",
    "        return s[len(\"CSV:\"):] # On retourne tout ce qui suit \"CSV:\"\n",
    "    # Sinon, on tente de récupérer les lignes à partir de l'entête demandée dans le prompt\n",
    "    m = re.search(r\"(?mi)^description,type,syntax,semantic\\s*$\", s)\n",
    "    if m:\n",
    "        return s[m.start():] # On retourne tout à partir de l'entête\n",
    "    return s  # Sinon on retourne tout le texte\n",
    "\n",
    "# Fonction pour normaliser une ligne du CSV si les contraintes ne sont pas respectées\n",
    "def normalize_row(row: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    # Normalise les valeurs attendues\n",
    "    row[\"type\"] = str(row.get(\"type\",\"\")).strip().lower()\n",
    "    row[\"syntax\"] = str(row.get(\"syntax\",\"\")).strip().lower()\n",
    "    row[\"semantic\"] = str(row.get(\"semantic\",\"\")).strip().lower()\n",
    "\n",
    "    # Contraintes\n",
    "    type_ok = {\"statement\", \"proposition\"}\n",
    "    syntax_ok = {\"positive\", \"negative\"}\n",
    "    semantic_ok = {\"positive\", \"negative\", \"neutral\"}\n",
    "\n",
    "    # Normalisation si besoin\n",
    "    if row[\"type\"] not in type_ok:\n",
    "        row[\"type\"] = \"statement\" \n",
    "    if row[\"syntax\"] not in syntax_ok:\n",
    "        row[\"syntax\"] = \"positive\"\n",
    "    if row[\"semantic\"] not in semantic_ok:\n",
    "        row[\"semantic\"] = \"neutral\"\n",
    "    return row\n",
    "\n",
    "# Fonction pour parser le CSV retourné par le LLM en DataFrame pandas\n",
    "def parse_llm_csv(csv_text: str) -> pd.DataFrame:\n",
    "    csv_text = csv_text.strip()\n",
    "    if not csv_text.lower().startswith(\"description,type,syntax,semantic\"):\n",
    "        # Parfois le modèle met des espaces, on nettoie la première ligne\n",
    "        lines = csv_text.splitlines()\n",
    "        if lines:\n",
    "            header = lines[0].replace(\" \", \"\")\n",
    "            if header.lower() == \"description,type,syntax,semantic\":\n",
    "                lines[0] = \"description,type,syntax,semantic\"\n",
    "                csv_text = \"\\n\".join(lines)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(StringIO(csv_text), dtype=str, keep_default_na=False)\n",
    "    except Exception as e:\n",
    "        raise LLMBadCSV(f\"CSV illisible: {e}\")\n",
    "\n",
    "    # Colonnes minimales\n",
    "    expected_cols = [\"description\", \"type\", \"syntax\", \"semantic\"]\n",
    "    missing = [c for c in expected_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise LLMBadCSV(f\"Colonnes manquantes: {missing}\")\n",
    "\n",
    "    # Normalisation\n",
    "    df = df[expected_cols].copy()\n",
    "    df = df.apply(lambda r: pd.Series(normalize_row(r.to_dict())), axis=1)\n",
    "    return df\n",
    "\n",
    "def build_message(text: str) -> str:\n",
    "    message = f\"\"\"\n",
    "    But: extraire les idées principales DISTINCTES d'un texte pour analyse.\n",
    "\n",
    "    Règles:\n",
    "    1. N'utiliser QUE le contenu de la CONTRIBUTION.\n",
    "    2. Extraire la liste des idées DISTINCTES et PRINCIPALES.\n",
    "    - Chaque idée = une phrase claire, autonome, reformulée si nécessaire.\n",
    "    3. Pour CHAQUE idée, annoter:\n",
    "    - type: \"statement\" (constat) OU \"proposition\" (suggestion/recommandation/objectif).\n",
    "    - syntax: \"negative\" si la phrase contient une négation explicite (ex.: \"ne\", \"n'\", \"ne pas\", \"ne plus\", \"non\"), sinon \"positive\".\n",
    "    - semantic: \"positive\", \"negative\" ou \"neutral\" (valence sémantique).\n",
    "    4. Sortie STRICTEMENT en CSV avec entête EXACTE:\n",
    "    CSV:description,type,syntax,semantic\n",
    "    - Délimiteur: virgule.\n",
    "    - Chaque description entre guillemets doubles.\n",
    "    - Échapper tout guillemet interne par duplication (ex.: \"\"chat\"\").\n",
    "    - NE RIEN AJOUTER d'autre (pas de texte avant/après, pas de code fences).\n",
    "    - Pas de lignes vides.\n",
    "\n",
    "    Exemple: \"Les chats retombent sur leurs pattes. Les chats n'ont pas neuf vies. Il faut mieux prendre soin des chats pour prolonger leur vie.\" \n",
    "    CSV:description,type,syntax,semantic\n",
    "    \"Les chats retombent sur leurs pattes\",statement,positive,neutral\n",
    "    \"Les chats n'ont pas neuf vies\",statement,negative,negative\n",
    "    \"Il faut mieux prendre soin des chats pour prolonger leur vie\",proposition,positive,positive\n",
    "\n",
    "    CONTRIBUTION:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    return message\n",
    "\n",
    "# Fonction principale pour appeler le LLM et obtenir un DataFrame avec les idées extraites\n",
    "def call_llm_return_df(text: str) -> pd.DataFrame:\n",
    "    messages = build_message(text)\n",
    "    response = client.models.generate_content(model=MODEL_ID, contents=messages)\n",
    "    raw = response.text\n",
    "    csv_block = extract_csv_block(raw)\n",
    "    return parse_llm_csv(csv_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93586117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour itérer sur les contributions et extraire les idées en utilisant le LLM\n",
    "def extract_ideas_from_df(df_contrib: pd.DataFrame,\n",
    "                          text_col: str = \"contribution\",\n",
    "                          id_col: str = \"authorId\") -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for i, row in tqdm(df_contrib.iterrows(), total=len(df_contrib), desc=\"LLM extraction\"):\n",
    "        text = str(row[text_col]).strip()\n",
    "        auth = row[id_col]\n",
    "        if not text:\n",
    "            continue\n",
    "        try:\n",
    "            ideas_df = call_llm_return_df(text)\n",
    "        except Exception as e:\n",
    "            # On enregistre une ligne \"échec\" minimale pour traçabilité\n",
    "            ideas_df = pd.DataFrame([{\n",
    "                \"description\": f\"[PARSE_FAIL] {str(e)[:200]}\",\n",
    "                \"type\": \"statement\",\n",
    "                \"syntax\": \"positive\",\n",
    "                \"semantic\": \"neutral\"\n",
    "            }])\n",
    "\n",
    "        # Ajoute le contexte\n",
    "        ideas_df = ideas_df.copy()\n",
    "        ideas_df.insert(0, \"authorId\", auth)\n",
    "        ideas_df.insert(1, \"contrib_index\", i)\n",
    "        ideas_df.insert(2, \"contribution\", text)\n",
    "\n",
    "        # Concatène les idées extraites\n",
    "        concatenated_ideas = \" || \".join(ideas_df[\"description\"].tolist())\n",
    "        rows.append({\n",
    "            \"authorId\": auth,\n",
    "            \"contrib_index\": i,\n",
    "            \"contribution\": text,\n",
    "            \"ideas\": concatenated_ideas,\n",
    "            \"type\": \"statement\",  # Garder les valeurs par défaut pour type, syntax et semantic\n",
    "            \"syntax\": \"positive\",\n",
    "            \"semantic\": \"neutral\"\n",
    "        })\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"authorId\", \"contrib_index\", \"contribution\", \"ideas\", \"type\", \"syntax\", \"semantic\"])\n",
    "    out = pd.DataFrame(rows)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06d5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM extraction:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM extraction: 100%|██████████| 200/200 [1:43:47<00:00, 31.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction saved to ..\\data\\extraction_idees_principales_Gemini.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_path = data_dir / \"extraction_idees_principales_Gemini.csv\"\n",
    "if out_path.exists():\n",
    "    msg = f\"L'extraction a déjà été réalisée, {out_path}\"\n",
    "    print(msg)\n",
    "else:\n",
    "    result = extract_ideas_from_df(df_contrib[0:200])\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    result.to_csv(out_path, index=False)\n",
    "    print(f\"Extraction saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108ca97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorId</th>\n",
       "      <th>contrib_index</th>\n",
       "      <th>contribution</th>\n",
       "      <th>ideas</th>\n",
       "      <th>type</th>\n",
       "      <th>syntax</th>\n",
       "      <th>semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VXNlcjpjNDY0ZjllMy0xZDk4LTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>3</td>\n",
       "      <td>Repartir les richesses.  suppression de la tax...</td>\n",
       "      <td>Il faut répartir les richesses || Il faut supp...</td>\n",
       "      <td>statement</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VXNlcjo3MDdkM2IzOC0xZDYxLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>4</td>\n",
       "      <td>Les droits soient automatiques, comme nos devo...</td>\n",
       "      <td>Les droits doivent être automatiques, tout com...</td>\n",
       "      <td>statement</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VXNlcjoxZTNlOTExYi0xZTIwLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>7</td>\n",
       "      <td>réduire drastiquement la fraude fiscale. Impos...</td>\n",
       "      <td>Il faut réduire drastiquement la fraude fiscal...</td>\n",
       "      <td>statement</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VXNlcjo1ODljMWRiMy0xZDVhLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>8</td>\n",
       "      <td>diminuer le taux de prelevement pour les retra...</td>\n",
       "      <td>Diminuer le taux de prélèvement pour les retra...</td>\n",
       "      <td>statement</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VXNlcjo0OTUzNmNmYy0xZTIwLTExZTktOTRkMi1mYTE2M2...</td>\n",
       "      <td>9</td>\n",
       "      <td>TOUT FRANÇAIS DEVRA PAYER L’IMPÔT QU’IL SOIT D...</td>\n",
       "      <td>Tout Français devra payer l'impôt qu'il soit d...</td>\n",
       "      <td>statement</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            authorId  contrib_index  \\\n",
       "0  VXNlcjpjNDY0ZjllMy0xZDk4LTExZTktOTRkMi1mYTE2M2...              3   \n",
       "1  VXNlcjo3MDdkM2IzOC0xZDYxLTExZTktOTRkMi1mYTE2M2...              4   \n",
       "2  VXNlcjoxZTNlOTExYi0xZTIwLTExZTktOTRkMi1mYTE2M2...              7   \n",
       "3  VXNlcjo1ODljMWRiMy0xZDVhLTExZTktOTRkMi1mYTE2M2...              8   \n",
       "4  VXNlcjo0OTUzNmNmYy0xZTIwLTExZTktOTRkMi1mYTE2M2...              9   \n",
       "\n",
       "                                        contribution  \\\n",
       "0  Repartir les richesses.  suppression de la tax...   \n",
       "1  Les droits soient automatiques, comme nos devo...   \n",
       "2  réduire drastiquement la fraude fiscale. Impos...   \n",
       "3  diminuer le taux de prelevement pour les retra...   \n",
       "4  TOUT FRANÇAIS DEVRA PAYER L’IMPÔT QU’IL SOIT D...   \n",
       "\n",
       "                                               ideas       type    syntax  \\\n",
       "0  Il faut répartir les richesses || Il faut supp...  statement  positive   \n",
       "1  Les droits doivent être automatiques, tout com...  statement  positive   \n",
       "2  Il faut réduire drastiquement la fraude fiscal...  statement  positive   \n",
       "3  Diminuer le taux de prélèvement pour les retra...  statement  positive   \n",
       "4  Tout Français devra payer l'impôt qu'il soit d...  statement  positive   \n",
       "\n",
       "  semantic  \n",
       "0  neutral  \n",
       "1  neutral  \n",
       "2  neutral  \n",
       "3  neutral  \n",
       "4  neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb555b2",
   "metadata": {},
   "source": [
    "## 4. Notation humaine, hallucinations et idées séparées\n",
    "De nouveau, évaluer les 200 extractions et flag la présence d'hallucinations et d'idées séparées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2fc1c",
   "metadata": {},
   "source": [
    "## 5. Evaluation sur la pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23708499",
   "metadata": {},
   "source": [
    "## 6. Global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e453e7",
   "metadata": {},
   "source": [
    "Compte-rendu global"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
